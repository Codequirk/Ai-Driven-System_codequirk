import nltk
import json
from nltk.tokenize import word_tokenize

# ğŸ”¹ Explicitly set the path where nltk_data is stored
nltk.data.path.append(r"C:\Users\pragn.LAPTOP-DAHFBVDA\nltk_data")

# Load schema.json
try:
    with open("schema.json", "r") as file:
        schema = json.load(file)
    print("âœ… Schema loaded successfully:", schema)
except Exception as e:
    print("âŒ Error loading schema:", e)

# Sample query input
user_query = input("Enter your query: ")
print("ğŸ” User Query:", user_query)

# Tokenizing the input query
try:
    tokens = word_tokenize(user_query.lower())
    print("âœ… Tokenized Query:", tokens)
except Exception as e:
    print("âŒ Tokenization Error:", e)